# -*- coding: utf-8 -*-
"""syntheticdataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rS_6XD-wq9CbvWA86ao7TWOgXDBNml2P
"""

from google.colab import drive
drive.mount('/content/drive')

import os

base_path = "/content/drive/MyDrive/FYP_Dataset"

esa_path = os.path.join(base_path, "esa")
#jwst_path = os.path.join(base_path, "jwst")
space_images_path = os.path.join(base_path, "space images")

# Subfolders inside space_images
space_subfolders = ["constellations", "nebula", "galaxies", "cosmos", "stars", "planets", "moon"]
space_paths = [os.path.join(space_images_path, folder) for folder in space_subfolders]

import glob

# Example: list all images in ESA folder
esa_images = glob.glob(os.path.join(esa_path, "*.jpg"))  # or .png, .jpeg, etc.

# Example: list all images from 'space_images' subfolders
all_space_images = []
for path in space_paths:
    all_space_images.extend(glob.glob(os.path.join(path, "*.jpg")))

import cv2
import matplotlib.pyplot as plt

img = cv2.imread(esa_images[0])
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.imshow(img)
plt.title("ESA Sample Image")
plt.axis("off")
plt.show()

import glob
import os

# Base directory
base_path = "/content/drive/MyDrive/FYP_Dataset"

# Subfolders to include
all_folders = ["esa", "jwst", "space_images/constellations", "space_images/nebula",
               "space_images/galaxies", "space_images/cosmos", "space_images/stars",
               "space_images/planets", "space_images/moon"]

# Collect all images from the folders
all_images = []
for folder in all_folders:
    folder_path = os.path.join(base_path, folder)
    image_extensions = ["*.jpg", "*.jpeg", "*.png"]
    for ext in image_extensions:
        all_images.extend(glob.glob(os.path.join(folder_path, ext)))

import matplotlib.pyplot as plt
import cv2

#image_files = glob.glob(os.path.join(output_folder, "*.jpg"))

for i in range(5):
    img = cv2.imread(all_images[i])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img)
    plt.title(f"Image {i}")
    plt.axis("off")
    plt.show()

import os
from PIL import Image
import glob

# Define your input directory (where .tif files are)
input_dir = '/content/drive/MyDrive/FYP_Dataset/jwst'

# Define output directory (can be same or new)
output_dir = '/content/drive/MyDrive/FYP_Dataset/jwst_converted'
os.makedirs(output_dir, exist_ok=True)

# Loop through all .tif or .tiff files
tif_files = glob.glob(os.path.join(input_dir, '**/*.tif'), recursive=True) + \
            glob.glob(os.path.join(input_dir, '**/*.tiff'), recursive=True)

print(f"Found {len(tif_files)} TIFF images.")

for tif_path in tif_files:
    try:
        # Open and convert image
        with Image.open(tif_path) as img:
            # Convert to RGB (in case it's grayscale or multi-channel)
            img = img.convert('RGB')

            # Extract filename without extension
            base_name = os.path.splitext(os.path.basename(tif_path))[0]

            # Define output path (change extension here)
            output_path = os.path.join(output_dir, f"{base_name}.png")  # or use .png if preferred

            # Save as JPG or PNG
            img.save(output_path, 'PNG')  # or use 'PNG' if saving as PNG

            print(f"Converted: {base_name}.tif → {base_name}.png")
    except Exception as e:
        print(f"Failed to convert {tif_path}: {e}")

import cv2
import os
import glob

# Set input and output paths
input_folder = '/content/drive/MyDrive/FYP_Dataset/jwst'  # folder with .tif files
output_folder = '/content/drive/MyDrive/FYP_Dataset/jwst_converted'  # folder for resized .png files
os.makedirs(output_folder, exist_ok=True)

# Resize target (you can change to 1024 or 512 depending on what you want)
resize_dim = (1024, 1024)

# Get all .tif files
tif_images = glob.glob(os.path.join(input_folder, "*.tif"))

for img_path in tif_images:
    try:
        # Read the image using cv2
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

        if img is None:
            print(f"Skipping unreadable file: {img_path}")
            continue

        # Resize the image
        resized_img = cv2.resize(img, resize_dim, interpolation=cv2.INTER_AREA)

        # Build the output path
        filename = os.path.basename(img_path).replace(".tif", ".png")
        output_path = os.path.join(output_folder, filename)

        # Save the image as PNG
        cv2.imwrite(output_path, resized_img)
        print(f"Converted and saved: {output_path}")

    except Exception as e:
        print(f"Failed to process {img_path}: {e}")

pip install torch torchvision matplotlib

import os
import shutil
from glob import glob

source_dirs = [
    "/content/drive/MyDrive/FYP_Dataset/esa",
    "/content/drive/MyDrive/FYP_Dataset/jwst_converted",
    "/content/drive/MyDrive/FYP_Dataset/space images/constellations",
    "/content/drive/MyDrive/FYP_Dataset/space images/nebula",
    "/content/drive/MyDrive/FYP_Dataset/space images/galaxies",
    "/content/drive/MyDrive/FYP_Dataset/space images/cosmos",
    "/content/drive/MyDrive/FYP_Dataset/space images/stars",
]

combined_dir = "/content/drive/MyDrive/FYP_Dataset/combined"
os.makedirs(combined_dir, exist_ok=True)

image_extensions = ['*.jpg', '*.jpeg', '*.png']

for src in source_dirs:
    for ext in image_extensions:
        for img_path in glob(os.path.join(src, ext)):
            filename = os.path.basename(img_path)
            dest_path = os.path.join(combined_dir, filename)
            shutil.copy(img_path, dest_path)

combined_dir = "/content/drive/MyDrive/FYP_Dataset/combined"

from PIL import Image
Image.MAX_IMAGE_PIXELS = None

import os
import glob  # make sure this is imported!
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset

class HRImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_paths = []
        for ext in ["*.jpg", "*.jpeg", "*.png"]:
            self.image_paths.extend(glob.glob(os.path.join(image_dir, ext)))  # glob used correctly here
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            img = self.transform(img)
        return img

# Define transform for HR images
hr_transform = transforms.Compose([
    transforms.Resize((256, 256)),  # adjust size as needed
    transforms.ToTensor()
])

import torch
import torch.nn as nn

# Generator: Takes HR image and outputs fake LR image
class DownsampleGenerator(nn.Module):
    def __init__(self):
        super(DownsampleGenerator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),  # 256 → 128
            nn.ReLU(True),
            nn.Conv2d(64, 3, 4, 2, 1),  # 128 → 64
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)


# Discriminator: Classifies LR images as real or fake
class DownsampleDiscriminator(nn.Module):
    def __init__(self):
        super(DownsampleDiscriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),  # 16 → 8
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1),  # 8 → 4
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)

import torch.optim as optim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

G = DownsampleGenerator().to(device)
D = DownsampleDiscriminator().to(device)

criterion = nn.BCELoss()
lr = 0.0002

optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))

from torch.utils.data import DataLoader

# Assuming you already have HRImageDataset defined and loaded
dataset = HRImageDataset("/content/drive/MyDrive/FYP_Dataset/combined", transform=hr_transform)
print("Number of images found:", len(dataset))

dataloader = DataLoader(dataset, batch_size=8, shuffle=True)

for epoch in range(20):
    for i, real_hr in enumerate(dataloader):
        real_hr = real_hr.to(device)

        valid = torch.ones(real_hr.size(0), 1).to(device)
        fake = torch.zeros(real_hr.size(0), 1).to(device)

        # ---------------------
        #  Train Generator
        # ---------------------
        optimizer_G.zero_grad()

        fake_lr = G(real_hr)  # 1. Generate fake LR images first
        pred_fake = D(fake_lr)

        # Now you can calculate the losses
        l1_loss_fn = nn.L1Loss()
        pixel_loss = l1_loss_fn(fake_lr, torch.nn.functional.interpolate(real_hr, scale_factor=0.25, mode='bilinear'))
        adv_loss = criterion(pred_fake, valid)

        # Combine
        g_loss = 0.001 * adv_loss + 1.0 * pixel_loss

        g_loss.backward()
        optimizer_G.step()

        # ---------------------
        #  Train Discriminator
        # ---------------------
        optimizer_D.zero_grad()

        pred_real = D(torch.nn.functional.interpolate(real_hr, scale_factor=0.25, mode='bicubic'))
        loss_real = criterion(pred_real, valid)

        pred_fake = D(fake_lr.detach())
        loss_fake = criterion(pred_fake, fake)

        d_loss = (loss_real + loss_fake) / 2
        d_loss.backward()
        optimizer_D.step()

        if i % 10 == 0:
            print(f"[Epoch {epoch}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")

import torchvision.utils as vutils
vutils.save_image(fake_lr.data[:4], "fake_lr.png", normalize=True)

import matplotlib.pyplot as plt
import torchvision.transforms as T

# Transformation to convert tensor to PIL Image for display
to_pil = T.ToPILImage()

# Get a batch of high-resolution images
for i, real_hr in enumerate(dataloader):
    if i == 1:  # Only one batch
        break
    real_hr = real_hr.to(device)
    fake_lr = G(real_hr).detach().cpu()  # Generate low-res images
    real_hr = real_hr.cpu()

    # Display the first 3 image pairs
    for j in range(3):
        hr_img = to_pil(real_hr[j])
        lr_img = to_pil(fake_lr[j])

        fig, ax = plt.subplots(1, 2, figsize=(10, 5))
        ax[0].imshow(hr_img)
        ax[0].set_title("High-Resolution")
        ax[0].axis("off")

        ax[1].imshow(lr_img)
        ax[1].set_title("Generated Low-Resolution")
        ax[1].axis("off")
        plt.show()

hr_img.save(f"hr_sample_{j}.png")
lr_img.save(f"lr_sample_{j}.png")

"""

---

"""

# --- DATASET
class HRImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_paths = []
        for ext in ["*.jpg", "*.jpeg", "*.png"]:
            self.image_paths.extend(glob.glob(os.path.join(image_dir, ext)))
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            img = self.transform(img)
        return img

# --- TRANSFORMS
hr_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

import torch
import torch.nn as nn

# --- GENERATOR
class DownsampleGenerator(nn.Module):
    def __init__(self):
        super(DownsampleGenerator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 3, stride=2, padding=1),  # 256 -> 128
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, stride=2, padding=1), # 128 -> 64
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 3, 3, stride=1, padding=1),  # Keep size 64x64 but degrade quality
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)

# --- DISCRIMINATOR
class DownsampleDiscriminator(nn.Module):
    def __init__(self):
        super(DownsampleDiscriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.AdaptiveAvgPool2d((4, 4)),  # Reduce spatial size
            nn.Flatten(),
            nn.Linear(256 * 4 * 4, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# --- INITIALIZATION
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

G = DownsampleGenerator().to(device)
D = DownsampleDiscriminator().to(device)

criterion = nn.BCELoss()
l1_loss_fn = nn.L1Loss()

optimizer_G = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))

from torch.utils.data import DataLoader
# --- DATA LOADING
dataset = HRImageDataset("/content/drive/MyDrive/FYP_Dataset/combined", transform=hr_transform)
dataloader = DataLoader(dataset, batch_size=8, shuffle=True)
print("Number of images found:", len(dataset))

# --- TRAINING
for epoch in range(20):
    for i, real_hr in enumerate(dataloader):
        real_hr = real_hr.to(device)

        valid = torch.ones(real_hr.size(0), 1).to(device)
        fake = torch.zeros(real_hr.size(0), 1).to(device)

        # --- Train Generator
        optimizer_G.zero_grad()

        fake_lr = G(real_hr)
        pred_fake = D(fake_lr)

        # Combined loss: adversarial + pixel
        pixel_loss = l1_loss_fn(fake_lr, torch.nn.functional.interpolate(real_hr, scale_factor=0.25, mode='bilinear'))
        adv_loss = criterion(pred_fake, valid)
        g_loss = 0.001 * adv_loss + 1.0 * pixel_loss

        g_loss.backward()
        optimizer_G.step()

        # --- Train Discriminator
        optimizer_D.zero_grad()

        pred_real = D(torch.nn.functional.interpolate(real_hr, scale_factor=0.5, mode='bilinear'))
        loss_real = criterion(pred_real, valid)

        pred_fake = D(fake_lr.detach())
        loss_fake = criterion(pred_fake, fake)

        d_loss = (loss_real + loss_fake) / 2

        d_loss.backward()
        optimizer_D.step()

        if i % 20 == 0:
            print(f"[Epoch {epoch}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")

import torchvision.utils as vutils
import matplotlib.pyplot as plt
import torchvision.transforms as T

# --- Save Fake Low-Resolution Images
real_batch = next(iter(dataloader))
real_batch = real_batch.to(device)
fake_batch = G(real_batch).cpu()

# Save 8 images
#vutils.save_image(fake_batch.data[:8], "fake_lr_samples.png", normalize=True)
print("Fake LR samples saved!")

# --- Display a few Fake Images
to_pil = T.ToPILImage()

for idx in range(3):  # Display 3 images
    fake_img = to_pil(fake_batch[idx])
    plt.imshow(fake_img)
    plt.title(f"Generated Fake LR Image {idx+1}")
    plt.axis("off")
    plt.show()

import os

# --- Setup save directories ---
hr_save_dir = "/content/drive/MyDrive/FYP_Dataset/HR/"
lr_save_dir = "/content/drive/MyDrive/FYP_Dataset/LR/"

# Create folders if they do not exist
os.makedirs(hr_save_dir, exist_ok=True)
os.makedirs(lr_save_dir, exist_ok=True)

import os
import torchvision.transforms as T
import matplotlib.pyplot as plt

# --- Setup save directories ---
hr_save_dir = "/content/drive/MyDrive/FYP_Dataset/HR/"
lr_save_dir = "/content/drive/MyDrive/FYP_Dataset/LR/"

os.makedirs(hr_save_dir, exist_ok=True)
os.makedirs(lr_save_dir, exist_ok=True)

# --- Transformation to PIL for saving ---
to_pil = T.ToPILImage()

image_counter = 0  # to keep track across batches

for real_batch in dataloader:
    real_batch = real_batch.to(device)

    # Generate fake LR images
    fake_batch = G(real_batch).cpu()

    # Save each HR and LR image
    for idx in range(real_batch.size(0)):
        hr_img = to_pil(real_batch[idx].cpu())
        lr_img = to_pil(fake_batch[idx])

        # Save with unique index
        hr_img.save(os.path.join(hr_save_dir, f"HR_{image_counter}.png"))
        lr_img.save(os.path.join(lr_save_dir, f"LR_{image_counter}.png"))

        image_counter += 1  # Increment counter

print(f"All {image_counter} HR and LR image pairs saved successfully!")

# Display a few samples
for idx in range(8):  # first 3 images
    hr_img = to_pil(real_batch[idx].cpu())
    lr_img = to_pil(fake_batch[idx])

    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
    ax[0].imshow(hr_img)
    ax[0].set_title(f"High-Resolution {idx+1}")
    ax[0].axis("off")

    ax[1].imshow(lr_img)
    ax[1].set_title(f"Generated Low-Resolution {idx+1}")
    ax[1].axis("off")

    plt.show()

# Get multiple batches
for batch_idx, real_batch in enumerate(dataloader):

    real_batch = real_batch.to(device)
    fake_batch = G(real_batch).cpu()

    # Display first 3 images from the current batch
    for idx in range(3):
        hr_img = to_pil(real_batch[idx].cpu())
        lr_img = to_pil(fake_batch[idx])

        fig, ax = plt.subplots(1, 2, figsize=(10, 5))
        ax[0].imshow(hr_img)
        ax[0].set_title(f"High-Resolution (Batch {batch_idx}, Img {idx+1})")
        ax[0].axis("off")

        ax[1].imshow(lr_img)
        ax[1].set_title(f"Generated Low-Resolution (Batch {batch_idx}, Img {idx+1})")
        ax[1].axis("off")

        plt.show()

    # Optional: break after some batches if you don't want to loop forever
    if batch_idx == 2:  # Only show first 3 batches
        break

pip install torch torchvision

import os
from PIL import Image
import torch
import numpy as np
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
import torchvision.models as models
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim
import torch.optim as optim
from torchvision import datasets, models
import torchvision.utils as vutils

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class PairedImageDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform_lr, transform_hr):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.lr_images = sorted(os.listdir(lr_dir))
        self.hr_images = sorted(os.listdir(hr_dir))
        self.transform_lr = transform_lr
        self.transform_hr = transform_hr

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, idx):
        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_images[idx])).convert('RGB')
        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_images[idx])).convert('RGB')

        return self.transform_lr(lr_image), self.transform_hr(hr_image)

# Basic Residual Block
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(channels, channels, 3, 1, 1),
            nn.BatchNorm2d(channels),
            nn.PReLU(),
            nn.Conv2d(channels, channels, 3, 1, 1),
            nn.BatchNorm2d(channels)
        )

    def forward(self, x):
        return x + self.block(x)

# Generator
class Generator(nn.Module):
    def __init__(self, num_res_blocks=5):
        super().__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, 9, 1, 4),
            nn.PReLU()
        )
        self.res_blocks = nn.Sequential(*[ResidualBlock(64) for _ in range(num_res_blocks)])
        self.upsample = nn.Sequential(
            nn.Conv2d(64, 256, 3, 1, 1),
            nn.PixelShuffle(2),
            nn.PReLU(),
            nn.Conv2d(64, 256, 3, 1, 1),
            nn.PixelShuffle(2),
            nn.PReLU()
        )
        self.final = nn.Conv2d(64, 3, 9, 1, 4)

    def forward(self, x):
        x = self.conv1(x)
        res = self.res_blocks(x)
        x = self.upsample(res + x)
        return self.final(x)

# Discriminator
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        def block(in_channels, out_channels, stride=1):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, stride, 1),
                nn.BatchNorm2d(out_channels),
                nn.LeakyReLU(0.2, inplace=True)
            )

        self.model = nn.Sequential(
            block(3, 64, 2),
            block(64, 128, 2),
            block(128, 256, 2),
            block(256, 512, 2),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(512, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

class VGGFeatureExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        vgg19 = models.vgg19(pretrained=True).features
        self.features = nn.Sequential(*list(vgg19.children())[:18])
        for param in self.features.parameters():
            param.requires_grad = False

    def forward(self, img):
        return self.features(img)

# Paths
lr_dir = "/content/drive/MyDrive/FYP_Dataset/LR"
hr_dir = "/content/drive/MyDrive/FYP_Dataset/HR"

# Transforms
transform_lr = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor()
])
transform_hr = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# Dataset and Loader
dataset = PairedImageDataset(lr_dir, hr_dir, transform_lr, transform_hr)
loader = DataLoader(dataset, batch_size=8, shuffle=True)

# Models
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator = Generator().to(device)
discriminator = Discriminator().to(device)
feature_extractor = VGGFeatureExtractor().to(device)

# Losses
criterion_GAN = nn.BCELoss()
criterion_content = nn.MSELoss()

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

# Training
num_epochs = 20

output = "/content/drive/MyDrive/FYP_Dataset/SRGAN/"
os.makedirs(output, exist_ok=True)

for epoch in range(num_epochs):
    for i, (lr_imgs, hr_imgs) in enumerate(loader):
        lr_imgs = lr_imgs.to(device)
        hr_imgs = hr_imgs.to(device)
        valid = torch.ones((lr_imgs.size(0), 1), device=device)
        fake = torch.zeros((lr_imgs.size(0), 1), device=device)

        # --- Train Generator ---
        optimizer_G.zero_grad()
        sr_imgs = generator(lr_imgs)
        loss_content = criterion_content(feature_extractor(sr_imgs), feature_extractor(hr_imgs).detach())
        loss_GAN = criterion_GAN(discriminator(sr_imgs), valid)
        loss_G = loss_content + 1e-3 * loss_GAN
        loss_G.backward()
        optimizer_G.step()

        # --- Train Discriminator ---
        optimizer_D.zero_grad()
        loss_real = criterion_GAN(discriminator(hr_imgs), valid)
        loss_fake = criterion_GAN(discriminator(sr_imgs.detach()), fake)
        loss_D = (loss_real + loss_fake) / 2
        loss_D.backward()
        optimizer_D.step()

        if i % 50 == 0:
            # Disable gradients for inference
            with torch.no_grad():
                sr_imgs = generator(lr_imgs.to(device)).cpu()

            print(f"[Epoch {epoch}/{num_epochs}] [Batch {i}] "
                  f"[D loss: {loss_D.item():.4f}] [G loss: {loss_G.item():.4f}]")

            # Save output sample
            output_path = f"output/epoch_{epoch}_batch_{i}_SR.png"
            vutils.save_image(sr_imgs, output_path, normalize=True)

    # Save generator weights after each epoch
    torch.save(generator.state_dict(), f"output/SRGAN_G_epoch_{epoch}.pth")

generator.load_state_dict(torch.load("SRGAN_G.pth"))
generator.eval()
with torch.no_grad():
    lr_img, hr_img = dataset[0]
    lr_img = lr_img.unsqueeze(0).to(device)
    sr_img = generator(lr_img).squeeze().cpu()

# Display
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.imshow(transforms.ToPILImage()(lr_img.squeeze().cpu()))
plt.title("Low-Res")

plt.subplot(1, 2, 2)
plt.imshow(transforms.ToPILImage()(sr_img))
plt.title("Super-Resolved")
plt.show()